<source>
  @type tail
  path D:/Innova/Infra/Data/*/*/cpu.log 
  path_key path
  pos_file D:/Innova/Infra/Data/cpu.log.pos
  tag unified.log.cpu
  format csv
  keys timestamp,cpu_usage,cpu_temp,clock_speed,cache_miss_rate,power_consumption,memory_usage,disk_utilization,cpu_name,ip_address,server_health
  time_key timestamp
  time_format %d-%m-%Y %H:%M
  read_from_head true
</source>

<source>
  @type tail
  path D:/Innova/Infra/Data/*/*/app*.log
  path_key path
  pos_file D:/Innova/Infra/Data/app.log.pos
  tag unified.log.app

  <parse>
    @type multiline
    format_firstline /^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}\s+(INFO|ERROR|WARN|DEBUG|TRACE)\s+\d+\s+---\s+\[[^\]]+\]\s+[\w\.]+\s*:/
    format1 /^(?<message>.*)/
    multiline_flush_interval 0.1s
  </parse>

  time_key timestamp
  time_format %Y-%m-%d %H:%M:%S.%L
  read_from_head true
</source>


<filter unified.log.cpu>
  @type record_transformer
  enable_ruby true
  <record>
    log_type cpu_log
    environment ${record["path"].split('/')[-3]}
    server ${record["path"].split('/')[-2]}
  </record>
</filter>

<filter unified.log.app>
  @type record_transformer
  enable_ruby true
  <record>
    log_type app_log
    environment ${record["path"].split('/')[-3]}
    server ${record["path"].split('/')[-2]}
    app_name ${record["path"].split('/')[-1].split('.')[0]}
    message ${[record["message"], record["exception_type"], record["exception_message"], record["stacktrace"]].compact.join("\n")}
  </record>
  remove_keys stacktrace,exception_type,exception_message
</filter>

<match unified.log.*>
  @type kafka2
  brokers localhost:9092
  topic test
  <format>
    @type json
  </format>
  <buffer>
    flush_interval 1s
    chunk_limit_size 1k
    flush_thread_count 1
    flush_at_shutdown true
  </buffer>
</match>
